{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0f778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timestamp': '2025-06-20 23:32:23', 'event_type': 'feedback', 'metadata': {'sentiment': 'positive'}, 'content': \"I've been reviewing a fascinating document on the evaluation context in RAG (Retrieval-Augmented Generation) systems, and I'm excited to share some key takeaways ðŸ“š. The authors, Jasleen Singh, highlight the importance of accurate context evaluation in preventing hallucinations in LLMs (Large Language Models).\\n\\nOne of the surprising insights I gained is that the current focus on output fluency and grammar can actually lead to evaluating hallucinations after they happen, rather than preventing them in the first place. This got me thinking - what if we could evaluate the context before generation, to ensure that the information is relevant, up-to-date, and consistent? \\n\\nAccording to the document, this is a major missing piece in the current RAG pipeline. By evaluating the context before generation, we can improve the accuracy and trustworthiness of the responses. In fact, the authors propose a transparent RAG system that allows for user feedback to improve response and feedback. \\n\\nI think this is a game-changer for the field, and I'm excited to see how it will impact the development of more accurate and reliable LLMs. What are your thoughts on the importance of context evaluation in RAG systems? \\n\\nBased on work by Jasleen Singh (no publication date provided) #llm #RAG #contextevaluation\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def read_jsonl_file(filepath):\n",
    "    \"\"\"Read a JSONL file and return a list of JSON objects.\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data.append(json.loads(line.strip()))\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error parsing line: {line}\")\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "log_dir = \"/Users/DS Projects/VertexAi/llm_pdf_to_linkedin/app\"\n",
    "filename = \"feed.jsonl\"  # Replace with your filename\n",
    "filepath = os.path.join(log_dir, filename)\n",
    "\n",
    "if os.path.exists(filepath):\n",
    "    data = read_jsonl_file(filepath)\n",
    "    for entry in data:\n",
    "        print(entry)\n",
    "else:\n",
    "    print(f\"File not found: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e61c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_generator1\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "for bucket in client.list_buckets():\n",
    "    print(bucket.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ff54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmpdf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
